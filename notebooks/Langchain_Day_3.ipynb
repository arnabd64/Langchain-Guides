{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnabd64/Langchain-Guides/blob/main/notebooks/Langchain_Day_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain\n",
        "\n",
        "In this notebook we will delve into the following components:\n",
        "\n",
        "1. RunnableLambda\n",
        "2. RunnableSequence\n",
        "3. RunnableParallel\n",
        "\n",
        "* __What is a Runnable?__:\n",
        "\n",
        "A [Runnable](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface) is a specialized function built by langchain to ease the construction of complex chains. To execute a `Runnable`, there are 3 methods:\n",
        "\n",
        "1. `.invoke()`: Calls the `Runnable` on an input.\n",
        "2. `.stream()`: Streams the response of the `Runnable`.\n",
        "3. `.batch()`: Calls the `Runnable` on a list of inputs.\n",
        "\n",
        "__Note__: Mostly all the components in langchain are a `Runnable` which includes prompts, LLMs, chains, agents etc."
      ],
      "metadata": {
        "id": "ULjEjPdDG9c_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries"
      ],
      "metadata": {
        "id": "amTMFkXRKKDa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JREVueNEzyyA"
      },
      "outputs": [],
      "source": [
        "! pip install --no-cache-dir --progress-bar off \\\n",
        "    langchain==0.2.10 \\\n",
        "    langchain_community==0.2.10 \\\n",
        "    python-dotenv \\\n",
        "    > install.log"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import dotenv\n",
        "\n",
        "if not dotenv.load_dotenv(\"./.env\"):\n",
        "    raise FileNotFoundError"
      ],
      "metadata": {
        "id": "7QUH7aBW0LUf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Components"
      ],
      "metadata": {
        "id": "AOnSZyBBKQ5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda, RunnableSequence, RunnableBranch, RunnableParallel, RunnablePassthrough\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.llms.ollama import Ollama\n",
        "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.globals import set_debug\n",
        "from langchain.utils.math import cosine_similarity\n",
        "import math"
      ],
      "metadata": {
        "id": "l-p9oafJ0cyp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `RunnableLambda`\n",
        "\n",
        "A [`RunnableLambda`](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.RunnableLambda.html) is an interface between a regular method or `lambda` function and a `Runnable` or in simple words, `RunnableLambda` converts a python method into a `Runnable`. Please note that __a `RunnableLambda` method should only take a single input__."
      ],
      "metadata": {
        "id": "9Vsx9WYPKYBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "addition = RunnableLambda(lambda x: x + 9)\n",
        "multiply = RunnableLambda(lambda y: y * 3)"
      ],
      "metadata": {
        "id": "KQAvp0GoLkuD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Result of Addition:\", addition.invoke(6))\n",
        "print(\"Result of Multiplication:\", multiply.invoke(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1BOgnczMYMc",
        "outputId": "27465c73-d2b2-40ff-8833-39a9128fa452"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of Addition: 15\n",
            "Result of Multiplication: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `RunnableSequence`\n",
        "\n",
        "A [`RunnableSequence`](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.RunnableSequence.html) is a component that allows __chaining__ of multiple `Runnable` and even other `RunnableSequence` instances. This component can be considered as the _chain_ in LangChain. You can create a `RunnableSequence` using the `pipe (|)` operator."
      ],
      "metadata": {
        "id": "cYTFhdp8Mp3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Example__: Let's calculate the Area of a Circle given the radius. The mathematical formula is $A = \\pi r^2$. We can break this operation into 2 parts:\n",
        "\n",
        "1. Compute the square of `radius` ($r^2$)\n",
        "2. Multiply with `pi` ($\\pi$)\n",
        "\n",
        "We will be using both `RunnableSequence` as well as `pipe` operator."
      ],
      "metadata": {
        "id": "yxfk4wbwN1PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RunnableSequence\n",
        "circle_area = RunnableSequence(\n",
        "    RunnableLambda(lambda r: r * r, name=\"Radius-Squared\"),\n",
        "    RunnableLambda(lambda y: y * math.pi, name=\"Multiply Pi\"),\n",
        "    name=\"Area of Circle\"\n",
        ")\n",
        "\n",
        "# pipe operator\n",
        "circle_area_pipe = (\n",
        "    RunnableLambda(lambda r: r * r, name=\"Radius-Squared\")\n",
        "    | RunnableLambda(lambda y: y * math.pi, name=\"Multiply Pi\")\n",
        ")\n",
        "\n",
        "set_debug(True)\n",
        "print(\"Area of the Circle =\", circle_area.invoke(6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JHUMr-Y3AC-",
        "outputId": "73d1ed25-bd65-4b97-e130-d3151895ad15"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:Area of Circle] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": 6\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:Area of Circle > chain:Radius-Squared] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": 6\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:Area of Circle > chain:Radius-Squared] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": 36\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:Area of Circle > chain:Multiply Pi] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": 36\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:Area of Circle > chain:Multiply Pi] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": 113.09733552923255\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:Area of Circle] [4ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": 113.09733552923255\n",
            "}\n",
            "Area of the Circle = 113.09733552923255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Area of the Circle =\", circle_area_pipe.invoke(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZDJQdZyPiyV",
        "outputId": "6db2f264-7e52-4ccf-ba31-46e58aef7339"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": 2\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:Radius-Squared] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": 2\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:Radius-Squared] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": 4\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:Multiply Pi] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": 4\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:Multiply Pi] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": 12.566370614359172\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [5ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": 12.566370614359172\n",
            "}\n",
            "Area of the Circle = 12.566370614359172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `RunnableParallel`\n",
        "\n"
      ],
      "metadata": {
        "id": "QEA28hohPr3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A [`RunnableParallel`](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.RunnableParallel.html#langchain_core.runnables.base.RunnableParallel) allows you to run multiple `RunnableSequence` in parallel. This is useful when you want to run more than one sub-chains in parallel and also can be used inside of a `RunnableSequence`."
      ],
      "metadata": {
        "id": "N5zWZjTyYC3D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Pros & Cons Generator\n",
        "\n",
        "To better understand the Parallel execution of the chain, let's take an example.\n",
        "\n",
        "Our users to want to know the pros & cons of purchasing a product (e.g: A Car, An Electronic etc) that they like. We will first query the LLM to get a product description and then use `RunnableParallel` to retrieve the Pros and the Cons separately in Parallel and then combine those results into a single cohesive text."
      ],
      "metadata": {
        "id": "AiRwV7UNZKqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Product Description Chain\n",
        "\n",
        "A simple chain that generates a product description from a specified product name. This chain looks like:\n",
        "\n",
        "```markdown\n",
        "[product-name] --> [PromptTemplate] --> [Ollama] --> [OutputParser]\n",
        "```"
      ],
      "metadata": {
        "id": "9fHrhg9cen7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# description prompt\n",
        "description_prompt = {\n",
        "    \"template\": \"You are an assistant tasked with gathering information about a product that an user wants to know about. Get the information for: {product}\",\n",
        "    \"input_variables\": [\"product\"]\n",
        "}\n",
        "\n",
        "# LLM config\n",
        "config = {\n",
        "    \"name\": \"Ollama-Local\",\n",
        "    \"base_url\": os.getenv(\"HOST\"),\n",
        "    \"model\": os.getenv(\"MODEL\"),\n",
        "    \"temperature\": float(os.getenv(\"TEMPERATURE\")),\n",
        "    \"timeout\": int(os.getenv(\"TIMEOUT\")),\n",
        "    \"keep_alive\": 3600\n",
        "}\n",
        "\n",
        "# build a chain to gather information\n",
        "query_chain = (\n",
        "    PromptTemplate(**description_prompt)\n",
        "    | Ollama(**config)\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "2x29zspdCpJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pros Chain\n",
        "\n",
        "This chain will generate the Pros of purchasing the above product using the product description generated by the LLM using the Product Description Chain.\n",
        "\n",
        "```markdown\n",
        "[product-description] --> [PromptTemplate] --> [Ollama] --> [OutputParser]\n",
        "```"
      ],
      "metadata": {
        "id": "x8LIPmgSgzfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pros Chain\n",
        "#Prompt template\n",
        "pros_prompt = {\n",
        "    \"input_variables\": [\"description\"],\n",
        "    \"template\": \"Write down exactly 5 points on why should the user purchase a product according to the following product description:\\n{description}\"\n",
        "}\n",
        "\n",
        "# build the chain\n",
        "pros_chain = (\n",
        "    PromptTemplate(**pros_prompt)\n",
        "    | Ollama(**config)\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "7ODh1Zq0IBsP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cons Chain\n",
        "\n",
        "Similar to the Pros chain, the Cons chain is used to generate the cons of purchasing the product using the product description generated by the LLM using the Product Description Chain.\n",
        "\n",
        "```markdown\n",
        "[product-description] --> [PromptTemplate] --> [Ollama] --> [OutputParser]\n",
        "```"
      ],
      "metadata": {
        "id": "KhakdrpVhPfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cons Chain\n",
        "# Prompt\n",
        "cons_prompt = {\n",
        "    \"input_variables\": [\"description\"],\n",
        "    \"template\": \"Write down exactly 5 points on why the user should not purchase a product according to the following product description:\\n{description}\"\n",
        "}\n",
        "\n",
        "# cons chain\n",
        "cons_chain = (\n",
        "    PromptTemplate(**cons_prompt)\n",
        "    | Ollama(**config)\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "3W2Y4egGLNem"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine Chain\n",
        "\n",
        "This chain will combine both the outputs of both the Pros Chain and Cons Chain and generate a single pros & cons summary.\n",
        "\n",
        "```markdown\n",
        "[Pros-Chain]\n",
        "    |\n",
        "    |---->\n",
        "            [PromptTemplate] ---> [Ollama] ---> [OutputParser]\n",
        "    |---->\n",
        "    |\n",
        "[Cons-Chain]\n",
        "```"
      ],
      "metadata": {
        "id": "cwmp3JmbiAWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the Chains\n",
        "combine_prompt = {\n",
        "    \"input_variables\": [\"pros\", \"cons\"],\n",
        "    \"template\": \"You are tasked with summarizing the advantages and disadvantages of purchasing a product from the given list: Firstly, the advatages:\\n{pros} and finally the disadvantages:\\n{cons}\"\n",
        "}\n",
        "\n",
        "# combine chain\n",
        "combine_chain = (\n",
        "    PromptTemplate(**combine_prompt)\n",
        "    | Ollama(**config)\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "_nREjGhrV0gW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chaining all things Together\n",
        "\n",
        "Now we link all the chains together to form a single chain that takes in the name of a product and generates a single response containing the pros and cons of that product."
      ],
      "metadata": {
        "id": "bZvw09sQiUAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_chain = (\n",
        "    query_chain\n",
        "    | RunnableParallel(pros=pros_chain, cons=cons_chain)\n",
        "    | combine_chain\n",
        ")"
      ],
      "metadata": {
        "id": "tnrzsd91PWsv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the Chain"
      ],
      "metadata": {
        "id": "PE-xJX69jJHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_debug(False)\n",
        "response = final_chain.invoke({\"product\": \"Porsche 911 Turbo GT\"})"
      ],
      "metadata": {
        "id": "UdoBdo6Fqkw9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWsBpBeLstx2",
        "outputId": "bacdd7ab-b988-4173-df92-c535b49a6b07"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Advantages of purchasing a Porsche 911 Turbo S or GT3 RS include superior performance, advanced engineering features, luxurious interior design, exceptional track performance, and innovative design elements. These factors make them attractive choices for discerning buyers seeking a high-performance vehicle with premium aesthetics.\n",
            "\n",
            "However, potential disadvantages associated with these products might include concerns about their authenticity due to not being officially recognized by Porsche AG; limited warranty coverage; potentially lower resale value on the secondary market; difficulty in finding authorized service centers and obtaining genuine parts; and higher insurance costs due to the potential risks associated with unauthorized modifications or replicas. Therefore, careful consideration should be given to these factors before making a purchasing decision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_config = {\n",
        "    # Set the prompts\n",
        "    \"prompts\": {\n",
        "        # prompt to get a description of the product\n",
        "        \"description\": {\n",
        "            \"name\": \"Prompt-Generate-Product_Description\",\n",
        "            \"input_variables\": [\"product\"],\n",
        "            \"template\": \"You are an assistant tasked with gathering information about a product that an user wants to know about. Get the information for: {product}\"\n",
        "        },\n",
        "\n",
        "        # prompt to get the advantages of a purchase\n",
        "        \"pros\": {\n",
        "            \"name\": \"Prompt-Generate-Advantages\",\n",
        "            \"input_variables\": [\"description\"],\n",
        "            \"template\": \"List exactly 5 reasons why the user should purchase the product described as:\\n{description}\"\n",
        "        },\n",
        "\n",
        "        # prompt to get the disadvantages of a purchse\n",
        "        \"cons\": {\n",
        "            \"name\": \"Prompt-Generate-Disadvantages\",\n",
        "            \"input_variables\": [\"description\"],\n",
        "            \"template\": \"List exactly 5 reasons why the user should not purchase the product described as:\\n{description}\"\n",
        "        },\n",
        "\n",
        "        # prompt to combine both the pros and cons into a single summary\n",
        "        \"combine\": {\n",
        "            \"name\": \"Prompt-Summarize-Outputs\",\n",
        "            \"input_variables\": [\"pros\", \"cons\"],\n",
        "            \"template\": \"Write down 3 points each on the Advantages and Disadvantages of making a purchase for a product. The advantages of a purcahse are:\\n{pros} and the disadvantages of a purcashe are:\\n{cons}\"\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"llm-config\": {\n",
        "        \"name\": \"Ollama-Local\",\n",
        "        \"base_url\": os.getenv(\"HOST\"),\n",
        "        \"model\": os.getenv(\"MODEL\"),\n",
        "        \"temperature\": float(os.getenv(\"TEMPERATURE\")),\n",
        "        \"timeout\": int(os.getenv(\"TIMEOUT\")),\n",
        "        \"keep_alive\": 3600\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "cNLg5RlsuOv7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_pipe = (\n",
        "    # 1. Description Generator Chain\n",
        "    PromptTemplate(**chain_config[\"prompts\"][\"description\"])\n",
        "    | Ollama(**chain_config[\"llm-config\"])\n",
        "    | StrOutputParser()\n",
        "\n",
        "    # 2. Parallel chains\n",
        "    | RunnableParallel(\n",
        "        # 2A. Generate Advantages\n",
        "        pros = (\n",
        "            PromptTemplate(**chain_config[\"prompts\"][\"pros\"])\n",
        "            | Ollama(**chain_config[\"llm-config\"])\n",
        "            | StrOutputParser()\n",
        "        ),\n",
        "        # 2B. Generate Disadvantages\n",
        "        cons = (\n",
        "            PromptTemplate(**chain_config[\"prompts\"][\"cons\"])\n",
        "            | Ollama(**chain_config[\"llm-config\"])\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # 3. Combine the Advantages & Disadvantages\n",
        "    | PromptTemplate(**chain_config[\"prompts\"][\"combine\"])\n",
        "    | Ollama(**chain_config[\"llm-config\"])\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "cvlp3ZsLEC9x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_debug(False)\n",
        "response = chain_pipe.invoke({\"product\": \"Porsche 911 Carrera RS\"})"
      ],
      "metadata": {
        "id": "UTJ6gxnsxW0O"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "ANi-V6RQzZC4",
        "outputId": "6b16e44d-b20b-4620-e089-42a3aa02a572",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " You've done a fantastic job summarizing both the advantages and disadvantages of purchasing a Porsche 911 Carrera RS! Here are some additional points on each side:\n",
            "\n",
            "Advantages (Continued):\n",
            "6. Resale Value: With its limited production, high demand, and enduring appeal, the Porsche 911 Carrera RS often retains a significant portion of its value over time. This can make it a wise investment for some buyers who are looking to resell their vehicle later.\n",
            "7. Prestige: Owning such an iconic sports car can bring prestige and admiration from peers, adding a level of social status to the ownership experience.\n",
            "\n",
            "Disadvantages (Continued):\n",
            "6. Maintenance Costs: High-performance cars often require more frequent and costly maintenance than regular vehicles. This is due to their complex engines and advanced technology systems.\n",
            "7. Limited Comfort Features: While the Carrera RS offers exceptional performance, it may not provide as much comfort or luxury features compared to other Porsche models or competing sports cars in its class.\n",
            "8. Parking Challenges: Due to its size and distinctive design, finding parking spaces for a Porsche 911 Carerra RS can be difficult, especially in urban environments with limited space.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_subchain = RunnableSequence(\n",
        "    # 1. Product Description Generator Sub-Chain\n",
        "    RunnableSequence(\n",
        "        PromptTemplate(**chain_config[\"prompts\"][\"description\"]),\n",
        "        Ollama(**chain_config[\"llm-config\"]),\n",
        "        StrOutputParser(),\n",
        "        name=\"Chain-Generate-Product_Description\"\n",
        "    ),\n",
        "\n",
        "    # 2. Generate Advantages & Disadvantages\n",
        "    RunnableParallel(\n",
        "        pros = RunnableSequence(\n",
        "            # 2A. Generate the Advantages\n",
        "            PromptTemplate(**chain_config[\"prompts\"][\"pros\"]),\n",
        "            Ollama(**chain_config[\"llm-config\"]),\n",
        "            StrOutputParser(),\n",
        "            name=\"Chain-Generate-Advantages\"\n",
        "        ),\n",
        "        cons = RunnableSequence(\n",
        "            # 2B. Generate the Disadvantages\n",
        "            PromptTemplate(**chain_config[\"prompts\"][\"cons\"]),\n",
        "            Ollama(**chain_config[\"llm-config\"]),\n",
        "            StrOutputParser(),\n",
        "            name=\"Chain-Generate-Disadvantages\"\n",
        "        )\n",
        "    ),\n",
        "\n",
        "    # 3. Combine the Results\n",
        "    RunnableSequence(\n",
        "        PromptTemplate(**chain_config[\"prompts\"][\"combine\"]),\n",
        "        Ollama(**chain_config[\"llm-config\"]),\n",
        "        StrOutputParser(),\n",
        "        name=\"Chain-Summarize-Output\"\n",
        "    ),\n",
        "    name=\"Parent-Chain\"\n",
        ")"
      ],
      "metadata": {
        "id": "pYXdEYTxEBPk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_debug(False)\n",
        "chain_subchain.invoke({\"product\": \"Porsche Carrera RS\"})"
      ],
      "metadata": {
        "id": "3Rvpmur0FnxP",
        "outputId": "4e37fe96-6e8c-433b-cbd4-c85dd45b0c24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-0326a4d77afd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mset_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchain_subchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"product\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Porsche Carrera RS\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2873\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2875\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2876\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         return (\n\u001b[0;32m--> 346\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    347\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    702\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m                 )\n\u001b[1;32m    881\u001b[0m             ]\n\u001b[0;32m--> 882\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    883\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             output = (\n\u001b[0;32m--> 727\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    728\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/ollama.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             final_chunk = super()._stream_with_aggregation(\n\u001b[0m\u001b[1;32m    414\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/ollama.py\u001b[0m in \u001b[0;36m_stream_with_aggregation\u001b[0;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m     ) -> GenerationChunk:\n\u001b[1;32m    328\u001b[0m         \u001b[0mfinal_chunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGenerationChunk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_generate_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stream_response_to_generation_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/ollama.py\u001b[0m in \u001b[0;36m_create_generate_stream\u001b[0;34m(self, prompt, stop, images, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     ) -> Iterator[str]:\n\u001b[1;32m    175\u001b[0m         \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"images\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         yield from self._create_stream(\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36miter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0mpending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         for chunk in self.iter_content(\n\u001b[0m\u001b[1;32m    866\u001b[0m             \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_unicode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_unicode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         ):\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/utils.py\u001b[0m in \u001b[0;36mstream_decode_response_unicode\u001b[0;34m(iterator, r)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetincrementaldecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \"\"\"\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb\";\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LdcLitg_BIj8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}